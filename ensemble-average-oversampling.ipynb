{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Prepocessing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom collections import Counter\ndf=pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\ndf=df.drop(labels=[\"BQ\",\"EL\"],axis=1)\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-29T01:44:31.347171Z","iopub.execute_input":"2023-07-29T01:44:31.347578Z","iopub.status.idle":"2023-07-29T01:44:31.537666Z","shell.execute_reply.started":"2023-07-29T01:44:31.347546Z","shell.execute_reply":"2023-07-29T01:44:31.536631Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"               AB            AF           AH          AM          AR  \\\ncount  617.000000    617.000000   617.000000  617.000000  617.000000   \nmean     0.477149   3502.013221   118.624513   38.968552   10.128242   \nstd      0.468388   2300.322717   127.838950   69.728226   10.518877   \nmin      0.081187    192.593280    85.200147    3.177522    8.138688   \n25%      0.252107   2197.345480    85.200147   12.270314    8.138688   \n50%      0.354659   3120.318960    85.200147   20.533110    8.138688   \n75%      0.559763   4361.637390   113.739540   39.139886    8.138688   \nmax      6.161666  28688.187660  1910.123198  630.518230  178.943634   \n\n               AX          AY          AZ           BC           BD   ...  \\\ncount  617.000000  617.000000  617.000000   617.000000    617.000000  ...   \nmean     5.545576    0.060320   10.566447     8.053012   5350.388655  ...   \nstd      2.551696    0.416817    4.350645    65.166943   3021.326641  ...   \nmin      0.699861    0.025578    3.396778     1.229900   1693.624320  ...   \n25%      4.128294    0.025578    8.129580     1.229900   4155.702870  ...   \n50%      5.031912    0.025578   10.461320     1.229900   4997.960730  ...   \n75%      6.431634    0.036845   12.969516     5.081244   6035.885700  ...   \nmax     38.270880   10.315851   38.971568  1463.693448  53060.599240  ...   \n\n               FL           FR          FS          GB           GE  \\\ncount  616.000000   617.000000  615.000000  617.000000   617.000000   \nmean     5.433199     3.533905    0.421501   20.724856   131.714987   \nstd     11.496257    50.181948    1.305365    9.991907   144.181524   \nmin      0.173229     0.497060    0.067730    4.102182    72.611063   \n25%      0.173229     0.497060    0.067730   14.036718    72.611063   \n50%      3.028141     1.131000    0.250601   18.771436    72.611063   \n75%      6.238814     1.512060    0.535067   25.608406   127.591671   \nmax    137.932739  1244.227020   31.365763  135.781294  1497.351958   \n\n                  GF          GH          GI          GL       Class  \ncount     617.000000  617.000000  617.000000  616.000000  617.000000  \nmean    14679.595398   31.489716   50.584437    8.530961    0.175041  \nstd     19352.959387    9.864239   36.266251   10.327010    0.380310  \nmin        13.038894    9.432735    0.897628    0.001129    0.000000  \n25%      2798.992584   25.034888   23.011684    0.124392    0.000000  \n50%      7838.273610   30.608946   41.007968    0.337827    0.000000  \n75%     19035.709240   36.863947   67.931664   21.978000    0.000000  \nmax    143790.071200   81.210825  191.194764   21.978000    1.000000  \n\n[8 rows x 54 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AB</th>\n      <th>AF</th>\n      <th>AH</th>\n      <th>AM</th>\n      <th>AR</th>\n      <th>AX</th>\n      <th>AY</th>\n      <th>AZ</th>\n      <th>BC</th>\n      <th>BD</th>\n      <th>...</th>\n      <th>FL</th>\n      <th>FR</th>\n      <th>FS</th>\n      <th>GB</th>\n      <th>GE</th>\n      <th>GF</th>\n      <th>GH</th>\n      <th>GI</th>\n      <th>GL</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>...</td>\n      <td>616.000000</td>\n      <td>617.000000</td>\n      <td>615.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>617.000000</td>\n      <td>616.000000</td>\n      <td>617.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.477149</td>\n      <td>3502.013221</td>\n      <td>118.624513</td>\n      <td>38.968552</td>\n      <td>10.128242</td>\n      <td>5.545576</td>\n      <td>0.060320</td>\n      <td>10.566447</td>\n      <td>8.053012</td>\n      <td>5350.388655</td>\n      <td>...</td>\n      <td>5.433199</td>\n      <td>3.533905</td>\n      <td>0.421501</td>\n      <td>20.724856</td>\n      <td>131.714987</td>\n      <td>14679.595398</td>\n      <td>31.489716</td>\n      <td>50.584437</td>\n      <td>8.530961</td>\n      <td>0.175041</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.468388</td>\n      <td>2300.322717</td>\n      <td>127.838950</td>\n      <td>69.728226</td>\n      <td>10.518877</td>\n      <td>2.551696</td>\n      <td>0.416817</td>\n      <td>4.350645</td>\n      <td>65.166943</td>\n      <td>3021.326641</td>\n      <td>...</td>\n      <td>11.496257</td>\n      <td>50.181948</td>\n      <td>1.305365</td>\n      <td>9.991907</td>\n      <td>144.181524</td>\n      <td>19352.959387</td>\n      <td>9.864239</td>\n      <td>36.266251</td>\n      <td>10.327010</td>\n      <td>0.380310</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.081187</td>\n      <td>192.593280</td>\n      <td>85.200147</td>\n      <td>3.177522</td>\n      <td>8.138688</td>\n      <td>0.699861</td>\n      <td>0.025578</td>\n      <td>3.396778</td>\n      <td>1.229900</td>\n      <td>1693.624320</td>\n      <td>...</td>\n      <td>0.173229</td>\n      <td>0.497060</td>\n      <td>0.067730</td>\n      <td>4.102182</td>\n      <td>72.611063</td>\n      <td>13.038894</td>\n      <td>9.432735</td>\n      <td>0.897628</td>\n      <td>0.001129</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.252107</td>\n      <td>2197.345480</td>\n      <td>85.200147</td>\n      <td>12.270314</td>\n      <td>8.138688</td>\n      <td>4.128294</td>\n      <td>0.025578</td>\n      <td>8.129580</td>\n      <td>1.229900</td>\n      <td>4155.702870</td>\n      <td>...</td>\n      <td>0.173229</td>\n      <td>0.497060</td>\n      <td>0.067730</td>\n      <td>14.036718</td>\n      <td>72.611063</td>\n      <td>2798.992584</td>\n      <td>25.034888</td>\n      <td>23.011684</td>\n      <td>0.124392</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.354659</td>\n      <td>3120.318960</td>\n      <td>85.200147</td>\n      <td>20.533110</td>\n      <td>8.138688</td>\n      <td>5.031912</td>\n      <td>0.025578</td>\n      <td>10.461320</td>\n      <td>1.229900</td>\n      <td>4997.960730</td>\n      <td>...</td>\n      <td>3.028141</td>\n      <td>1.131000</td>\n      <td>0.250601</td>\n      <td>18.771436</td>\n      <td>72.611063</td>\n      <td>7838.273610</td>\n      <td>30.608946</td>\n      <td>41.007968</td>\n      <td>0.337827</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.559763</td>\n      <td>4361.637390</td>\n      <td>113.739540</td>\n      <td>39.139886</td>\n      <td>8.138688</td>\n      <td>6.431634</td>\n      <td>0.036845</td>\n      <td>12.969516</td>\n      <td>5.081244</td>\n      <td>6035.885700</td>\n      <td>...</td>\n      <td>6.238814</td>\n      <td>1.512060</td>\n      <td>0.535067</td>\n      <td>25.608406</td>\n      <td>127.591671</td>\n      <td>19035.709240</td>\n      <td>36.863947</td>\n      <td>67.931664</td>\n      <td>21.978000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6.161666</td>\n      <td>28688.187660</td>\n      <td>1910.123198</td>\n      <td>630.518230</td>\n      <td>178.943634</td>\n      <td>38.270880</td>\n      <td>10.315851</td>\n      <td>38.971568</td>\n      <td>1463.693448</td>\n      <td>53060.599240</td>\n      <td>...</td>\n      <td>137.932739</td>\n      <td>1244.227020</td>\n      <td>31.365763</td>\n      <td>135.781294</td>\n      <td>1497.351958</td>\n      <td>143790.071200</td>\n      <td>81.210825</td>\n      <td>191.194764</td>\n      <td>21.978000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 54 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def cut(x):\n    if x=='A':\n        return 0\n    else:\n        return 1\ndf['EJ']=df['EJ'].map(cut)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T01:44:34.637758Z","iopub.execute_input":"2023-07-29T01:44:34.638156Z","iopub.status.idle":"2023-07-29T01:44:34.644468Z","shell.execute_reply.started":"2023-07-29T01:44:34.638123Z","shell.execute_reply":"2023-07-29T01:44:34.643346Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"features = df.iloc[:,1:-1]\ntarget=df['Class']\nfeatures","metadata":{"execution":{"iopub.status.busy":"2023-07-29T01:44:38.730165Z","iopub.execute_input":"2023-07-29T01:44:38.730550Z","iopub.status.idle":"2023-07-29T01:44:38.763549Z","shell.execute_reply.started":"2023-07-29T01:44:38.730519Z","shell.execute_reply":"2023-07-29T01:44:38.762337Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"           AB          AF          AH          AM         AR        AX  \\\n0    0.209377  3109.03329   85.200147   22.394407   8.138688  0.699861   \n1    0.145282   978.76416   85.200147   36.968889   8.138688  3.632190   \n2    0.470030  2635.10654   85.200147   32.360553   8.138688  6.732840   \n3    0.252107  3819.65177  120.201618   77.112203   8.138688  3.685344   \n4    0.380297  3733.04844   85.200147   14.103738   8.138688  3.942255   \n..        ...         ...         ...         ...        ...       ...   \n612  0.149555  3130.05946  123.763599    9.513984  13.020852  3.499305   \n613  0.435846  5462.03438   85.200147   46.551007  15.973224  5.979825   \n614  0.427300  2459.10720  130.138587   55.355778  10.005552  8.070549   \n615  0.363205  1263.53524   85.200147   23.685856   8.138688  7.981959   \n616  0.482849  2672.53426  546.663930  112.006102   8.138688  3.198099   \n\n           AY         AZ          BC         BD   ...         FI         FL  \\\n0    0.025578   9.812214    5.555634  4126.58731  ...   3.583450   7.298162   \n1    0.025578  13.517790    1.229900  5496.92824  ...  10.358927   0.173229   \n2    0.025578  12.824570    1.229900  5135.78024  ...  11.626917   7.709560   \n3    0.025578  11.053708    1.229900  4169.67738  ...  14.852022   6.122162   \n4    0.054810   3.396778  102.151980  5728.73412  ...  13.666727   8.153058   \n..        ...        ...         ...         ...  ...        ...        ...   \n612  0.077343   8.545512    2.804172  4157.68439  ...   9.879296   0.173229   \n613  0.025882  12.622906    3.777550  5654.07556  ...  10.910227  10.223150   \n614  0.025578  15.408390    1.229900  5888.87769  ...  12.029366   0.173229   \n615  0.025578   7.524588    1.229900  4517.86560  ...   8.026928   9.256996   \n616  0.116928   3.396778    7.948668  2818.01707  ...   7.745765   0.173229   \n\n           FR        FS         GB          GE            GF         GH  \\\n0     1.73855  0.094822  11.339138   72.611063   2003.810319  22.136229   \n1     0.49706  0.568932   9.292698   72.611063  27981.562750  29.135430   \n2     0.97556  1.198821  37.077772   88.609437  13676.957810  28.022851   \n3     0.49706  0.284466  18.529584   82.416803   2094.262452  39.948656   \n4    48.50134  0.121914  16.408728  146.109943   8524.370502  45.381316   \n..        ...       ...        ...         ...           ...        ...   \n612   1.26092  0.067730   8.967128  217.148554   8095.932828  24.640462   \n613   1.24236  0.426699  35.896418  496.994214   3085.308063  29.648928   \n614   0.49706  0.067730  19.962092  128.896894   6474.652866  26.166072   \n615   0.78764  0.670527  24.594488   72.611063   1965.343176  25.116750   \n616   1.14492  0.149006  13.673940   72.611063   6850.484442  45.745974   \n\n             GI         GL  \n0     69.834944   0.120343  \n1     32.131996  21.978000  \n2     35.192676   0.196941  \n3     90.493248   0.155829  \n4     36.262628   0.096614  \n..          ...        ...  \n612   69.191944  21.978000  \n613  124.808872   0.145340  \n614  119.559420  21.978000  \n615   37.155112   0.184622  \n616  114.842372  21.978000  \n\n[617 rows x 54 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AB</th>\n      <th>AF</th>\n      <th>AH</th>\n      <th>AM</th>\n      <th>AR</th>\n      <th>AX</th>\n      <th>AY</th>\n      <th>AZ</th>\n      <th>BC</th>\n      <th>BD</th>\n      <th>...</th>\n      <th>FI</th>\n      <th>FL</th>\n      <th>FR</th>\n      <th>FS</th>\n      <th>GB</th>\n      <th>GE</th>\n      <th>GF</th>\n      <th>GH</th>\n      <th>GI</th>\n      <th>GL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.209377</td>\n      <td>3109.03329</td>\n      <td>85.200147</td>\n      <td>22.394407</td>\n      <td>8.138688</td>\n      <td>0.699861</td>\n      <td>0.025578</td>\n      <td>9.812214</td>\n      <td>5.555634</td>\n      <td>4126.58731</td>\n      <td>...</td>\n      <td>3.583450</td>\n      <td>7.298162</td>\n      <td>1.73855</td>\n      <td>0.094822</td>\n      <td>11.339138</td>\n      <td>72.611063</td>\n      <td>2003.810319</td>\n      <td>22.136229</td>\n      <td>69.834944</td>\n      <td>0.120343</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.145282</td>\n      <td>978.76416</td>\n      <td>85.200147</td>\n      <td>36.968889</td>\n      <td>8.138688</td>\n      <td>3.632190</td>\n      <td>0.025578</td>\n      <td>13.517790</td>\n      <td>1.229900</td>\n      <td>5496.92824</td>\n      <td>...</td>\n      <td>10.358927</td>\n      <td>0.173229</td>\n      <td>0.49706</td>\n      <td>0.568932</td>\n      <td>9.292698</td>\n      <td>72.611063</td>\n      <td>27981.562750</td>\n      <td>29.135430</td>\n      <td>32.131996</td>\n      <td>21.978000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.470030</td>\n      <td>2635.10654</td>\n      <td>85.200147</td>\n      <td>32.360553</td>\n      <td>8.138688</td>\n      <td>6.732840</td>\n      <td>0.025578</td>\n      <td>12.824570</td>\n      <td>1.229900</td>\n      <td>5135.78024</td>\n      <td>...</td>\n      <td>11.626917</td>\n      <td>7.709560</td>\n      <td>0.97556</td>\n      <td>1.198821</td>\n      <td>37.077772</td>\n      <td>88.609437</td>\n      <td>13676.957810</td>\n      <td>28.022851</td>\n      <td>35.192676</td>\n      <td>0.196941</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.252107</td>\n      <td>3819.65177</td>\n      <td>120.201618</td>\n      <td>77.112203</td>\n      <td>8.138688</td>\n      <td>3.685344</td>\n      <td>0.025578</td>\n      <td>11.053708</td>\n      <td>1.229900</td>\n      <td>4169.67738</td>\n      <td>...</td>\n      <td>14.852022</td>\n      <td>6.122162</td>\n      <td>0.49706</td>\n      <td>0.284466</td>\n      <td>18.529584</td>\n      <td>82.416803</td>\n      <td>2094.262452</td>\n      <td>39.948656</td>\n      <td>90.493248</td>\n      <td>0.155829</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.380297</td>\n      <td>3733.04844</td>\n      <td>85.200147</td>\n      <td>14.103738</td>\n      <td>8.138688</td>\n      <td>3.942255</td>\n      <td>0.054810</td>\n      <td>3.396778</td>\n      <td>102.151980</td>\n      <td>5728.73412</td>\n      <td>...</td>\n      <td>13.666727</td>\n      <td>8.153058</td>\n      <td>48.50134</td>\n      <td>0.121914</td>\n      <td>16.408728</td>\n      <td>146.109943</td>\n      <td>8524.370502</td>\n      <td>45.381316</td>\n      <td>36.262628</td>\n      <td>0.096614</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>612</th>\n      <td>0.149555</td>\n      <td>3130.05946</td>\n      <td>123.763599</td>\n      <td>9.513984</td>\n      <td>13.020852</td>\n      <td>3.499305</td>\n      <td>0.077343</td>\n      <td>8.545512</td>\n      <td>2.804172</td>\n      <td>4157.68439</td>\n      <td>...</td>\n      <td>9.879296</td>\n      <td>0.173229</td>\n      <td>1.26092</td>\n      <td>0.067730</td>\n      <td>8.967128</td>\n      <td>217.148554</td>\n      <td>8095.932828</td>\n      <td>24.640462</td>\n      <td>69.191944</td>\n      <td>21.978000</td>\n    </tr>\n    <tr>\n      <th>613</th>\n      <td>0.435846</td>\n      <td>5462.03438</td>\n      <td>85.200147</td>\n      <td>46.551007</td>\n      <td>15.973224</td>\n      <td>5.979825</td>\n      <td>0.025882</td>\n      <td>12.622906</td>\n      <td>3.777550</td>\n      <td>5654.07556</td>\n      <td>...</td>\n      <td>10.910227</td>\n      <td>10.223150</td>\n      <td>1.24236</td>\n      <td>0.426699</td>\n      <td>35.896418</td>\n      <td>496.994214</td>\n      <td>3085.308063</td>\n      <td>29.648928</td>\n      <td>124.808872</td>\n      <td>0.145340</td>\n    </tr>\n    <tr>\n      <th>614</th>\n      <td>0.427300</td>\n      <td>2459.10720</td>\n      <td>130.138587</td>\n      <td>55.355778</td>\n      <td>10.005552</td>\n      <td>8.070549</td>\n      <td>0.025578</td>\n      <td>15.408390</td>\n      <td>1.229900</td>\n      <td>5888.87769</td>\n      <td>...</td>\n      <td>12.029366</td>\n      <td>0.173229</td>\n      <td>0.49706</td>\n      <td>0.067730</td>\n      <td>19.962092</td>\n      <td>128.896894</td>\n      <td>6474.652866</td>\n      <td>26.166072</td>\n      <td>119.559420</td>\n      <td>21.978000</td>\n    </tr>\n    <tr>\n      <th>615</th>\n      <td>0.363205</td>\n      <td>1263.53524</td>\n      <td>85.200147</td>\n      <td>23.685856</td>\n      <td>8.138688</td>\n      <td>7.981959</td>\n      <td>0.025578</td>\n      <td>7.524588</td>\n      <td>1.229900</td>\n      <td>4517.86560</td>\n      <td>...</td>\n      <td>8.026928</td>\n      <td>9.256996</td>\n      <td>0.78764</td>\n      <td>0.670527</td>\n      <td>24.594488</td>\n      <td>72.611063</td>\n      <td>1965.343176</td>\n      <td>25.116750</td>\n      <td>37.155112</td>\n      <td>0.184622</td>\n    </tr>\n    <tr>\n      <th>616</th>\n      <td>0.482849</td>\n      <td>2672.53426</td>\n      <td>546.663930</td>\n      <td>112.006102</td>\n      <td>8.138688</td>\n      <td>3.198099</td>\n      <td>0.116928</td>\n      <td>3.396778</td>\n      <td>7.948668</td>\n      <td>2818.01707</td>\n      <td>...</td>\n      <td>7.745765</td>\n      <td>0.173229</td>\n      <td>1.14492</td>\n      <td>0.149006</td>\n      <td>13.673940</td>\n      <td>72.611063</td>\n      <td>6850.484442</td>\n      <td>45.745974</td>\n      <td>114.842372</td>\n      <td>21.978000</td>\n    </tr>\n  </tbody>\n</table>\n<p>617 rows × 54 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"id=df['Id']\nid","metadata":{"execution":{"iopub.status.busy":"2023-07-29T01:44:41.468284Z","iopub.execute_input":"2023-07-29T01:44:41.468925Z","iopub.status.idle":"2023-07-29T01:44:41.478148Z","shell.execute_reply.started":"2023-07-29T01:44:41.468881Z","shell.execute_reply":"2023-07-29T01:44:41.476835Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0      000ff2bfdfe9\n1      007255e47698\n2      013f2bd269f5\n3      043ac50845d5\n4      044fb8a146ec\n           ...     \n612    fd3dafe738fd\n613    fd895603f071\n614    fd8ef6377f76\n615    fe1942975e40\n616    ffcca4ded3bb\nName: Id, Length: 617, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestRegressor\nX_full, y_full = features,target\nn_samples = X_full.shape[0] # 样本\nn_features = X_full.shape[1] # 特征\nprint(n_samples)\nprint(n_features)\n\n#首先确定我们希望放入的缺失值数据的比例，在这里我假设是50%，可以自己改动\nrng = np.random.RandomState(0)\nmissing_rate = 0.5\nn_missing_samples = int(np.floor(n_samples * n_features *missing_rate))\n#np.floor  向下取整\n#所有数据要随机遍布在数据集的各行各列当中，而一个确实的数据会需要一盒行索引和一个列索引\n#如果能够创造一个数组，就可以利用索引来赋空值\n\nX_missing_reg = X_full.copy()\n# 查看缺失情况\nmissing = X_missing_reg .isna().sum()\nmissing = pd.DataFrame(data={'特征': missing.index,'缺失值个数':missing.values})\n#通过~取反，选取不包含数字0的行\nmissing = missing[~missing['缺失值个数'].isin([0])]\n# 缺失比例\nmissing['缺失比例'] =  missing['缺失值个数']/X_missing_reg .shape[0]\nX_df = X_missing_reg.isnull().sum()\n# 得出列名 缺失值最少的列名 到 缺失值最多的列名\ncolname = X_df[~X_df.isin([0])].sort_values().index.values\n# 缺失值从小到大的特征顺序\nsortindex = []\nfor i in colname:\n    sortindex.append(X_missing_reg.columns.tolist().index(str(i)))\n# 遍历所有的特征，从缺失最少的开始进行填补，每完成一次回归预测，就将预测值放到原本的特征矩阵中，再继续填补下一个特征\nfor i in sortindex:\n    # 构建我们的新特征矩阵和新标签\n    df = X_missing_reg  # 充当中间数据集\n    fillc = df.iloc[:, i]  # 缺失值最少的特征列\n    # 除了第 i 特征列，剩下的特征列+原有的完整标签 = 新的特征矩阵\n    df = pd.concat([df.drop(df.columns[i], axis=1), pd.DataFrame(y_full)], axis=1)\n    # 在新特征矩阵中，对含有缺失值的列，进行0的填补 ，没循环一次，用0填充的列越来越少\n    df_0 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0).fit_transform(df)\n    # 找出训练集和测试集\n    # 标签\n    Ytrain = fillc[fillc.notnull()]  # 没有缺失的部分，就是 Y_train\n    Ytest = fillc[fillc.isnull()]  # 不是需要Ytest的值，而是Ytest的索引\n    # 特征矩阵\n    Xtrain = df_0[Ytrain.index, :]\n    Xtest = df_0[Ytest.index, :]  # 有缺失值的特征情况\n    rfc = RandomForestRegressor(n_estimators=100)  # 实例化\n    rfc = rfc.fit(Xtrain, Ytrain)  # 训练\n    Ypredict = rfc.predict(Xtest)  # 预测结果，就是要填补缺失值的值\n    # 将填补好的特征返回到我们的原始的特征矩阵中\n    X_missing_reg.loc[X_missing_reg.iloc[:, i].isnull(), X_missing_reg.columns[i]] = Ypredict\n# 最后，再次查看缺失值是否全部被替换\nmissing2 = X_missing_reg.isna().sum()\nmissing2 = pd.DataFrame(data={'列名': missing2.index, '缺失值个数': missing2.values})\n# 通过~取反，选取不包含数字0的行\nmissing3=missing2[~missing2['缺失值个数'].isin([0])]\nprint(missing2)\nprint(missing3)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T01:44:44.010023Z","iopub.execute_input":"2023-07-29T01:44:44.010420Z","iopub.status.idle":"2023-07-29T01:44:59.347394Z","shell.execute_reply.started":"2023-07-29T01:44:44.010385Z","shell.execute_reply":"2023-07-29T01:44:59.346177Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"617\n54\n     列名  缺失值个数\n0    AB      0\n1    AF      0\n2    AH      0\n3    AM      0\n4    AR      0\n5    AX      0\n6    AY      0\n7    AZ      0\n8    BC      0\n9   BD       0\n10   BN      0\n11   BP      0\n12   BR      0\n13   BZ      0\n14   CB      0\n15   CC      0\n16  CD       0\n17   CF      0\n18   CH      0\n19   CL      0\n20   CR      0\n21   CS      0\n22   CU      0\n23  CW       0\n24   DA      0\n25   DE      0\n26   DF      0\n27   DH      0\n28   DI      0\n29   DL      0\n30   DN      0\n31   DU      0\n32   DV      0\n33   DY      0\n34   EB      0\n35   EE      0\n36   EG      0\n37   EH      0\n38   EJ      0\n39   EP      0\n40   EU      0\n41   FC      0\n42  FD       0\n43   FE      0\n44   FI      0\n45   FL      0\n46   FR      0\n47   FS      0\n48   GB      0\n49   GE      0\n50   GF      0\n51   GH      0\n52   GI      0\n53   GL      0\nEmpty DataFrame\nColumns: [列名, 缺失值个数]\nIndex: []\n","output_type":"stream"}]},{"cell_type":"code","source":"df1=pd.concat([id,X_missing_reg,df['Class']],axis=1)\ndf1.to_csv('/kaggle/working/total.csv')\ndf1","metadata":{"execution":{"iopub.status.busy":"2023-07-29T01:45:05.918032Z","iopub.execute_input":"2023-07-29T01:45:05.919046Z","iopub.status.idle":"2023-07-29T01:45:05.989757Z","shell.execute_reply.started":"2023-07-29T01:45:05.919006Z","shell.execute_reply":"2023-07-29T01:45:05.988758Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"               Id        AB          AF          AH          AM         AR  \\\n0    000ff2bfdfe9  0.209377  3109.03329   85.200147   22.394407   8.138688   \n1    007255e47698  0.145282   978.76416   85.200147   36.968889   8.138688   \n2    013f2bd269f5  0.470030  2635.10654   85.200147   32.360553   8.138688   \n3    043ac50845d5  0.252107  3819.65177  120.201618   77.112203   8.138688   \n4    044fb8a146ec  0.380297  3733.04844   85.200147   14.103738   8.138688   \n..            ...       ...         ...         ...         ...        ...   \n612  fd3dafe738fd  0.149555  3130.05946  123.763599    9.513984  13.020852   \n613  fd895603f071  0.435846  5462.03438   85.200147   46.551007  15.973224   \n614  fd8ef6377f76  0.427300  2459.10720  130.138587   55.355778  10.005552   \n615  fe1942975e40  0.363205  1263.53524   85.200147   23.685856   8.138688   \n616  ffcca4ded3bb  0.482849  2672.53426  546.663930  112.006102   8.138688   \n\n           AX        AY         AZ          BC  ...         FL        FR  \\\n0    0.699861  0.025578   9.812214    5.555634  ...   7.298162   1.73855   \n1    3.632190  0.025578  13.517790    1.229900  ...   0.173229   0.49706   \n2    6.732840  0.025578  12.824570    1.229900  ...   7.709560   0.97556   \n3    3.685344  0.025578  11.053708    1.229900  ...   6.122162   0.49706   \n4    3.942255  0.054810   3.396778  102.151980  ...   8.153058  48.50134   \n..        ...       ...        ...         ...  ...        ...       ...   \n612  3.499305  0.077343   8.545512    2.804172  ...   0.173229   1.26092   \n613  5.979825  0.025882  12.622906    3.777550  ...  10.223150   1.24236   \n614  8.070549  0.025578  15.408390    1.229900  ...   0.173229   0.49706   \n615  7.981959  0.025578   7.524588    1.229900  ...   9.256996   0.78764   \n616  3.198099  0.116928   3.396778    7.948668  ...   0.173229   1.14492   \n\n           FS         GB          GE            GF         GH          GI  \\\n0    0.094822  11.339138   72.611063   2003.810319  22.136229   69.834944   \n1    0.568932   9.292698   72.611063  27981.562750  29.135430   32.131996   \n2    1.198821  37.077772   88.609437  13676.957810  28.022851   35.192676   \n3    0.284466  18.529584   82.416803   2094.262452  39.948656   90.493248   \n4    0.121914  16.408728  146.109943   8524.370502  45.381316   36.262628   \n..        ...        ...         ...           ...        ...         ...   \n612  0.067730   8.967128  217.148554   8095.932828  24.640462   69.191944   \n613  0.426699  35.896418  496.994214   3085.308063  29.648928  124.808872   \n614  0.067730  19.962092  128.896894   6474.652866  26.166072  119.559420   \n615  0.670527  24.594488   72.611063   1965.343176  25.116750   37.155112   \n616  0.149006  13.673940   72.611063   6850.484442  45.745974  114.842372   \n\n            GL  Class  \n0     0.120343      1  \n1    21.978000      0  \n2     0.196941      0  \n3     0.155829      0  \n4     0.096614      1  \n..         ...    ...  \n612  21.978000      0  \n613   0.145340      0  \n614  21.978000      0  \n615   0.184622      0  \n616  21.978000      0  \n\n[617 rows x 56 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>AB</th>\n      <th>AF</th>\n      <th>AH</th>\n      <th>AM</th>\n      <th>AR</th>\n      <th>AX</th>\n      <th>AY</th>\n      <th>AZ</th>\n      <th>BC</th>\n      <th>...</th>\n      <th>FL</th>\n      <th>FR</th>\n      <th>FS</th>\n      <th>GB</th>\n      <th>GE</th>\n      <th>GF</th>\n      <th>GH</th>\n      <th>GI</th>\n      <th>GL</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000ff2bfdfe9</td>\n      <td>0.209377</td>\n      <td>3109.03329</td>\n      <td>85.200147</td>\n      <td>22.394407</td>\n      <td>8.138688</td>\n      <td>0.699861</td>\n      <td>0.025578</td>\n      <td>9.812214</td>\n      <td>5.555634</td>\n      <td>...</td>\n      <td>7.298162</td>\n      <td>1.73855</td>\n      <td>0.094822</td>\n      <td>11.339138</td>\n      <td>72.611063</td>\n      <td>2003.810319</td>\n      <td>22.136229</td>\n      <td>69.834944</td>\n      <td>0.120343</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>007255e47698</td>\n      <td>0.145282</td>\n      <td>978.76416</td>\n      <td>85.200147</td>\n      <td>36.968889</td>\n      <td>8.138688</td>\n      <td>3.632190</td>\n      <td>0.025578</td>\n      <td>13.517790</td>\n      <td>1.229900</td>\n      <td>...</td>\n      <td>0.173229</td>\n      <td>0.49706</td>\n      <td>0.568932</td>\n      <td>9.292698</td>\n      <td>72.611063</td>\n      <td>27981.562750</td>\n      <td>29.135430</td>\n      <td>32.131996</td>\n      <td>21.978000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>013f2bd269f5</td>\n      <td>0.470030</td>\n      <td>2635.10654</td>\n      <td>85.200147</td>\n      <td>32.360553</td>\n      <td>8.138688</td>\n      <td>6.732840</td>\n      <td>0.025578</td>\n      <td>12.824570</td>\n      <td>1.229900</td>\n      <td>...</td>\n      <td>7.709560</td>\n      <td>0.97556</td>\n      <td>1.198821</td>\n      <td>37.077772</td>\n      <td>88.609437</td>\n      <td>13676.957810</td>\n      <td>28.022851</td>\n      <td>35.192676</td>\n      <td>0.196941</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>043ac50845d5</td>\n      <td>0.252107</td>\n      <td>3819.65177</td>\n      <td>120.201618</td>\n      <td>77.112203</td>\n      <td>8.138688</td>\n      <td>3.685344</td>\n      <td>0.025578</td>\n      <td>11.053708</td>\n      <td>1.229900</td>\n      <td>...</td>\n      <td>6.122162</td>\n      <td>0.49706</td>\n      <td>0.284466</td>\n      <td>18.529584</td>\n      <td>82.416803</td>\n      <td>2094.262452</td>\n      <td>39.948656</td>\n      <td>90.493248</td>\n      <td>0.155829</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>044fb8a146ec</td>\n      <td>0.380297</td>\n      <td>3733.04844</td>\n      <td>85.200147</td>\n      <td>14.103738</td>\n      <td>8.138688</td>\n      <td>3.942255</td>\n      <td>0.054810</td>\n      <td>3.396778</td>\n      <td>102.151980</td>\n      <td>...</td>\n      <td>8.153058</td>\n      <td>48.50134</td>\n      <td>0.121914</td>\n      <td>16.408728</td>\n      <td>146.109943</td>\n      <td>8524.370502</td>\n      <td>45.381316</td>\n      <td>36.262628</td>\n      <td>0.096614</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>612</th>\n      <td>fd3dafe738fd</td>\n      <td>0.149555</td>\n      <td>3130.05946</td>\n      <td>123.763599</td>\n      <td>9.513984</td>\n      <td>13.020852</td>\n      <td>3.499305</td>\n      <td>0.077343</td>\n      <td>8.545512</td>\n      <td>2.804172</td>\n      <td>...</td>\n      <td>0.173229</td>\n      <td>1.26092</td>\n      <td>0.067730</td>\n      <td>8.967128</td>\n      <td>217.148554</td>\n      <td>8095.932828</td>\n      <td>24.640462</td>\n      <td>69.191944</td>\n      <td>21.978000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>613</th>\n      <td>fd895603f071</td>\n      <td>0.435846</td>\n      <td>5462.03438</td>\n      <td>85.200147</td>\n      <td>46.551007</td>\n      <td>15.973224</td>\n      <td>5.979825</td>\n      <td>0.025882</td>\n      <td>12.622906</td>\n      <td>3.777550</td>\n      <td>...</td>\n      <td>10.223150</td>\n      <td>1.24236</td>\n      <td>0.426699</td>\n      <td>35.896418</td>\n      <td>496.994214</td>\n      <td>3085.308063</td>\n      <td>29.648928</td>\n      <td>124.808872</td>\n      <td>0.145340</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>614</th>\n      <td>fd8ef6377f76</td>\n      <td>0.427300</td>\n      <td>2459.10720</td>\n      <td>130.138587</td>\n      <td>55.355778</td>\n      <td>10.005552</td>\n      <td>8.070549</td>\n      <td>0.025578</td>\n      <td>15.408390</td>\n      <td>1.229900</td>\n      <td>...</td>\n      <td>0.173229</td>\n      <td>0.49706</td>\n      <td>0.067730</td>\n      <td>19.962092</td>\n      <td>128.896894</td>\n      <td>6474.652866</td>\n      <td>26.166072</td>\n      <td>119.559420</td>\n      <td>21.978000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>615</th>\n      <td>fe1942975e40</td>\n      <td>0.363205</td>\n      <td>1263.53524</td>\n      <td>85.200147</td>\n      <td>23.685856</td>\n      <td>8.138688</td>\n      <td>7.981959</td>\n      <td>0.025578</td>\n      <td>7.524588</td>\n      <td>1.229900</td>\n      <td>...</td>\n      <td>9.256996</td>\n      <td>0.78764</td>\n      <td>0.670527</td>\n      <td>24.594488</td>\n      <td>72.611063</td>\n      <td>1965.343176</td>\n      <td>25.116750</td>\n      <td>37.155112</td>\n      <td>0.184622</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>616</th>\n      <td>ffcca4ded3bb</td>\n      <td>0.482849</td>\n      <td>2672.53426</td>\n      <td>546.663930</td>\n      <td>112.006102</td>\n      <td>8.138688</td>\n      <td>3.198099</td>\n      <td>0.116928</td>\n      <td>3.396778</td>\n      <td>7.948668</td>\n      <td>...</td>\n      <td>0.173229</td>\n      <td>1.14492</td>\n      <td>0.149006</td>\n      <td>13.673940</td>\n      <td>72.611063</td>\n      <td>6850.484442</td>\n      <td>45.745974</td>\n      <td>114.842372</td>\n      <td>21.978000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>617 rows × 56 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install tabpfn","metadata":{"execution":{"iopub.status.busy":"2023-07-29T01:45:08.831028Z","iopub.execute_input":"2023-07-29T01:45:08.831421Z","iopub.status.idle":"2023-07-29T01:45:21.577064Z","shell.execute_reply.started":"2023-07-29T01:45:08.831387Z","shell.execute_reply":"2023-07-29T01:45:21.575724Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting tabpfn\n  Downloading tabpfn-0.1.9-py3-none-any.whl (156 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.6/156.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (1.23.5)\nRequirement already satisfied: pyyaml>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (6.0)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (2.31.0)\nRequirement already satisfied: scikit-learn>=0.24.2 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (1.2.2)\nRequirement already satisfied: torch>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from tabpfn) (2.0.0+cpu)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->tabpfn) (2023.5.7)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.11.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.2->tabpfn) (3.1.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9.0->tabpfn) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9.0->tabpfn) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9.0->tabpfn) (1.3.0)\nInstalling collected packages: tabpfn\nSuccessfully installed tabpfn-0.1.9\n","output_type":"stream"}]},{"cell_type":"code","source":"import xgboost\nclass Ensemble():\n    def __init__(self):\n        self.imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n\n        self.classifiers =[xgboost.XGBClassifier(n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,colsample_bytree=0.85),\n                           xgboost.XGBClassifier(),\n\n                           TabPFNClassifier(N_ensemble_configurations=24),\n                           TabPFNClassifier(N_ensemble_configurations=64)]\n    \n    def fit(self, X, y):\n        y = y.values\n        unique_classes, y = np.unique(y, return_inverse=True)\n        self.classes_ = unique_classes\n        # first_category = X.EJ.unique()[0]\n        # X.EJ = X.EJ.eq(first_category).astype('int')\n        \n        X = self.imputer.fit_transform(X)\n        for classifier in self.classifiers:\n            if classifier == self.classifiers[2] or classifier == self.classifiers[3]:\n                classifier.fit(X,y,overwrite_warning =True)\n            else :\n                classifier.fit(X, y)\n     \n    def predict_proba(self, x):\n        x = self.imputer.transform(x)\n\n        probabilities = np.stack([classifier.predict_proba(x) for classifier in self.classifiers])\n        averaged_probabilities = np.mean(probabilities, axis=0)\n        class_0_est_instances = averaged_probabilities[:, 0].sum()\n        others_est_instances = averaged_probabilities[:, 1:].sum()\n        \n        # Weighted probabilities based on class imbalance\n        new_probabilities = averaged_probabilities * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(averaged_probabilities.shape[1])]])\n        \n        return new_probabilities / np.sum(new_probabilities, axis=1, keepdims=1)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T01:46:02.062940Z","iopub.execute_input":"2023-07-29T01:46:02.063356Z","iopub.status.idle":"2023-07-29T01:46:02.245242Z","shell.execute_reply.started":"2023-07-29T01:46:02.063322Z","shell.execute_reply":"2023-07-29T01:46:02.244449Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"t = np.stack([[[0.1,0.9],[0.2,0.8]],[[0.4,0.6],[0.2,0.8]]])\nprint(t)\nnp.mean(t,axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T01:56:30.595870Z","iopub.execute_input":"2023-07-29T01:56:30.596267Z","iopub.status.idle":"2023-07-29T01:56:30.605409Z","shell.execute_reply.started":"2023-07-29T01:56:30.596239Z","shell.execute_reply":"2023-07-29T01:56:30.604392Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"[[[0.1 0.9]\n  [0.2 0.8]]\n\n [[0.4 0.6]\n  [0.2 0.8]]]\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([[0.25, 0.75],\n       [0.2 , 0.8 ]])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training step2: target to final class + oversampling","metadata":{}},{"cell_type":"code","source":"#train_X, val_X, train_y, val_y = train_test_split(df1.drop(labels=['Class','Id'],axis=1), df1['Class'], random_state = 2,test_size=0.3)\n#train_X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 2,test_size=0.4)\n#print(Counter(train_y))\n#from imblearn.over_sampling import SMOTE\n#smote_v = SMOTE(random_state=0)\n#X_train_smote, y_train_smote = smote_v.fit_resample(train_X,train_y)\n#Counter(y_train_smote)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\ndef balanced_log_loss1(y_true, y_pred):\n    nc = np.bincount(y_true)\n    return log_loss(y_true, y_pred, sample_weight = 1/nc[y_true], eps=1e-15, labels=[0, 1])\n\ndef cv_scores(models, X, y, n_splits = 3, scaling = []):\n    \"\"\"\n    Function to return cross validation log loss scores along with mean and standard deviation\n    Args:\n        model                            : untrained model\n        X (DataFrame, shape (m, n))      : feature dataframe\n        y (Series, shape (m, ))          : target variable\n        n_splits (scalar)                : number of folds for cross validation\n        scaling (array_like, shape (r, )): list of columns of X to be scaled (r <= n)\n        \n    Returns:\n        scores (array_like, shape (n_splits, )): list of cross validation log loss scores\n        mean (scalar): mean of the cross validation log loss scores\n        std (scalar) : standard deviation of the cross validation log loss scores\n    \"\"\"\n    scores = []\n    skf = StratifiedKFold(n_splits = n_splits, shuffle = True, random_state = 0)\n    for train_idx, val_idx in skf.split(X, y):#K-fold\n        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        print(Counter(y_train))\n        '''#utilizing weighting prob\n        from imblearn.over_sampling import SMOTE\n        smote_v = SMOTE(random_state=0)\n        X_train, y_train = smote_v.fit_resample(X_train, y_train)\n        '''\n        Counter(y_train)\n        X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n        #X_train, X_valid = minmax_scalar(X_train, X_valid, scaling)\n        for model in models:#cycle in diff models\n            if 'CatBoostClassifier' in str(model):\n                model.fit(X_train, y_train, eval_set = [(X_valid, y_valid)], verbose = 0)\n            else:\n                model.fit(X_train, y_train)\n        probabilities = np.stack([model.predict_proba(X_valid) for model in models])\n        averaged_probabilities = np.mean(probabilities, axis=0) #taking average of the samples\n        class_0_est_instances = averaged_probabilities[:, 0].sum()\n        others_est_instances = averaged_probabilities[:, 1:].sum()\n        \n        #Weighted probabilities based on class imbalance\n        new_probabilities = averaged_probabilities * np.array([[1/(class_0_est_instances if i==0 else others_est_instances) for i in range(averaged_probabilities.shape[1])]])\n        \n        final_prob = new_probabilities / np.sum(new_probabilities, axis=1, keepdims=1)\n        val_score = balanced_log_loss1(y_valid, final_prob[:,1])\n        scores.append(val_score)\n    mean, std = np.mean(scores), np.std(scores)\n    return scores, mean, std","metadata":{"execution":{"iopub.status.busy":"2023-07-29T02:31:07.877974Z","iopub.execute_input":"2023-07-29T02:31:07.878428Z","iopub.status.idle":"2023-07-29T02:31:07.890579Z","shell.execute_reply.started":"2023-07-29T02:31:07.878393Z","shell.execute_reply":"2023-07-29T02:31:07.889426Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from tabpfn import TabPFNClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression\nparams={\"iterations\": 10000,\n        \"verbose\": 1000,\n        \"learning_rate\": 0.001,\n        \"depth\": 4,\n        'auto_class_weights':'Balanced',\n        'loss_function':'MultiClass'}\ncb = CatBoostClassifier(**params)\ntab = TabPFNClassifier(N_ensemble_configurations=24)\nxgb = XGBClassifier(learning_rate=0.1,\n                      n_estimators=100,  # 树的个数--1000棵树建立xgboost\n                      random_state=1  # 随机数\n                      )\nlgb = LGBMClassifier(boosting_type='gbdt',\n                     num_leaves=31,\n                     max_depth=-1,\n                     learning_rate=0.1,\n                     n_estimators=100,\n                     objective='binary', # 默认是二分类\n                     random_state=1\n                     )\nxgb1 = xgboost.XGBClassifier(n_estimators=100,max_depth=3,learning_rate=0.2,subsample=0.9,colsample_bytree=0.85)\nxgb2 = xgboost.XGBClassifier()\ntab1 = TabPFNClassifier(N_ensemble_configurations=24)\ntab2 = TabPFNClassifier(N_ensemble_configurations=64)\n#log = LogisticRegression(random_state=0, max_iter=1000000)\nscore,mean,std = cv_scores([xgb1,xgb2,tab1,tab2],df1.drop(labels=['Class','Id'],axis=1), df1['Class'])\n#y_lab = np.argmax(val_preds, axis=1)\n#err = val_y - y_lab\n#acc = np.sum(err == 0)/len(y_lab)#0.9068825910931174 on val\n#acc\n#val_score = balanced_log_loss(val_y, val_preds)\nprint(score,mean,std)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T03:08:23.707033Z","iopub.execute_input":"2023-07-29T03:08:23.707852Z","iopub.status.idle":"2023-07-29T03:10:14.353063Z","shell.execute_reply.started":"2023-07-29T03:08:23.707815Z","shell.execute_reply":"2023-07-29T03:10:14.351899Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Loading model that can be used for inference only\nUsing a Transformer with 25.82 M parameters\nLoading model that can be used for inference only\nUsing a Transformer with 25.82 M parameters\nLoading model that can be used for inference only\nUsing a Transformer with 25.82 M parameters\nCounter({0: 339, 1: 72})\nCounter({0: 339, 1: 72})\nCounter({0: 340, 1: 72})\n[0.2539523902249138, 0.23797659606636723, 0.3478953255372041] 0.2799414372761617 0.048491268609889886\n","output_type":"stream"}]},{"cell_type":"code","source":"print(mean-2*std,mean+2*std)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T02:55:45.733775Z","iopub.execute_input":"2023-07-29T02:55:45.734159Z","iopub.status.idle":"2023-07-29T02:55:45.740381Z","shell.execute_reply.started":"2023-07-29T02:55:45.734131Z","shell.execute_reply":"2023-07-29T02:55:45.739147Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"0.18295890005638193 0.3769239744959415\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# testing and submission","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/working/test_with_al_y.csv')\ntest_df = test_df.drop('Unnamed: 0',axis=1)\nprint(test_df)\nX_test = np.array(test_df.iloc[:,1:59])\nprint(X_test)\ntest_preds = cb_clf.predict_proba(X_test)\n#print(test_preds)\nsample=pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/sample_submission.csv')\ntestres=test_preds.T[0]\nsample['class_1']=1-testres\nsample['class_0']=testres","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.to_csv('/kaggle/working/submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}